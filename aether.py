#!/usr/bin/env python3
"""
AetherOS - Invisible Intelligence, Everywhere
Version: 0.1.0 (Prototype)

A lightweight, intent-driven AI operating system.
No Apps, Just Aether.
"""

import os
import sys
import re
import json
import time
import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any
import subprocess

# Optional dependencies (install if available)
try:
    from llama_cpp import Llama
    LLAMA_AVAILABLE = True
except ImportError:
    LLAMA_AVAILABLE = False
    print("âš ï¸  llama-cpp-python not installed. LLM features disabled.")
    print("   Install: pip install llama-cpp-python")


class AetherConfig:
    """AetherOS Configuration"""
    
    # Paths
    HOME_DIR = Path.home() / ".aetheros"
    DB_PATH = HOME_DIR / "aether.db"
    MODEL_DIR = HOME_DIR / "models"
    CACHE_DIR = HOME_DIR / "cache"
    
    # Model settings
    MODEL_PATH = MODEL_DIR / "phi-3.5-mini-q4.gguf"
    CONTEXT_LENGTH = 4096
    MAX_TOKENS = 256
    
    # Performance
    FAST_MATCHER_CONFIDENCE_THRESHOLD = 0.9
    CACHE_SIZE = 1000
    
    @classmethod
    def init_dirs(cls):
        """Initialize AetherOS directories"""
        cls.HOME_DIR.mkdir(exist_ok=True)
        cls.MODEL_DIR.mkdir(exist_ok=True)
        cls.CACHE_DIR.mkdir(exist_ok=True)


class Intent:
    """Parsed user intent"""
    
    def __init__(self, category: str, action: str, parameters: Dict[str, Any],
                 confidence: float, method: str):
        self.category = category
        self.action = action
        self.parameters = parameters
        self.confidence = confidence
        self.method = method
    
    def __repr__(self):
        return f"Intent({self.action}, confidence={self.confidence:.2f}, method={self.method})"


class VectorStore:
    """SQLite-based lightweight vector store"""
    
    def __init__(self, db_path: Path):
        self.db_path = db_path
        self.conn = sqlite3.connect(str(db_path))
        self.init_db()
    
    def init_db(self):
        """Initialize database schema"""
        cursor = self.conn.cursor()
        
        # File index with FTS5 full-text search
        cursor.execute("""
        CREATE VIRTUAL TABLE IF NOT EXISTS files 
        USING fts5(
            filepath,
            filename,
            content,
            filetype,
            created_date,
            modified_date,
            size,
            tokenize = 'porter unicode61'
        )
        """)
        
        # Command history
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS command_history (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            command TEXT NOT NULL,
            intent TEXT,
            result TEXT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
            execution_time REAL
        )
        """)
        
        # Context memory
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS context_memory (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            key TEXT UNIQUE,
            value TEXT,
            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
        """)
        
        self.conn.commit()
    
    def search_files(self, query: str, filters: Optional[Dict] = None) -> List[Dict]:
        """Search files using FTS5"""
        cursor = self.conn.cursor()
        
        sql = "SELECT * FROM files WHERE files MATCH ?"
        params = [query]
        
        if filters:
            if 'filetype' in filters:
                sql += " AND filetype = ?"
                params.append(filters['filetype'])
        
        sql += " ORDER BY rank LIMIT 20"
        
        cursor.execute(sql, params)
        
        columns = [desc[0] for desc in cursor.description]
        results = [dict(zip(columns, row)) for row in cursor.fetchall()]
        
        return results
    
    def log_command(self, command: str, intent: str, result: str, exec_time: float):
        """Log command execution"""
        cursor = self.conn.cursor()
        cursor.execute("""
        INSERT INTO command_history (command, intent, result, execution_time)
        VALUES (?, ?, ?, ?)
        """, (command, intent, result, exec_time))
        self.conn.commit()


class FastMatcher:
    """Rule-based fast pattern matching (90% of cases)"""
    
    def __init__(self):
        self.patterns = self._load_patterns()
    
    def _load_patterns(self) -> Dict:
        """Load command patterns"""
        return {
            "file_search": {
                "patterns": [
                    r"(?P<time>ì–´ì œ|ì˜¤ëŠ˜|ì´ë²ˆì£¼)?\s*(?P<action>ë‹¤ìš´ë¡œë“œ|ìƒì„±|ìˆ˜ì •)í•œ?\s*(?P<type>pdf|jpg|docx|txt|png)?\s*íŒŒì¼\s*(?P<verb>ì°¾|ê²€ìƒ‰)",
                    r"(?P<filename>.+)\s*(íŒŒì¼)?\s*(?P<action>ì—´|ì‚­ì œ|ë³µì‚¬)",
                ],
                "action": "search_files"
            },
            "system_control": {
                "patterns": [
                    r"ë³¼ë¥¨\s*(?P<level>\d+)",
                    r"ë°ê¸°\s*(?P<level>\d+)",
                    r"(?P<app>\w+)\s*(ì•±|í”„ë¡œê·¸ë¨)?\s*ì‹¤í–‰",
                ],
                "action": "system_control"
            }
        }
    
    def match(self, user_input: str) -> Intent:
        """Try to match input against patterns"""
        for category, config in self.patterns.items():
            for pattern in config['patterns']:
                match = re.search(pattern, user_input)
                
                if match:
                    params = match.groupdict()
                    return Intent(
                        category=category,
                        action=config['action'],
                        parameters=params,
                        confidence=0.95,
                        method="rule_based"
                    )
        
        # No match
        return Intent(
            category="unknown",
            action="unknown",
            parameters={},
            confidence=0.0,
            method="none"
        )


class LLMEngine:
    """Lightweight LLM engine using Phi-3.5"""
    
    def __init__(self):
        self.model = None
        self.model_loaded = False
        
        if not LLAMA_AVAILABLE:
            print("âš ï¸  LLM engine disabled (llama-cpp-python not installed)")
            return
        
        if not AetherConfig.MODEL_PATH.exists():
            print(f"âš ï¸  Model not found: {AetherConfig.MODEL_PATH}")
            print("   Download model using: python scripts/download_models.py")
            return
    
    def load_model(self):
        """Load model (lazy loading)"""
        if self.model_loaded or not LLAMA_AVAILABLE:
            return
        
        print("âš¡ Loading AI model...")
        
        self.model = Llama(
            model_path=str(AetherConfig.MODEL_PATH),
            n_ctx=AetherConfig.CONTEXT_LENGTH,
            n_threads=os.cpu_count(),
            n_gpu_layers=0,  # CPU only (set to 35 for GPU)
            verbose=False
        )
        
        self.model_loaded = True
        print("âœ… AI model ready")
    
    def parse_intent(self, user_input: str, context: Dict) -> Intent:
        """Parse user intent using LLM"""
        if not self.model_loaded:
            self.load_model()
        
        if not self.model:
            return Intent("error", "llm_unavailable", {}, 0.0, "error")
        
        prompt = f"""<|system|>
You are AetherOS intent parser. Parse user commands into JSON.
Be concise and accurate.<|end|>
<|user|>
Parse this command into JSON format:
Command: {user_input}
Context: {json.dumps(context, ensure_ascii=False)}

Response format (JSON only, no explanation):
{{
    "action": "search_files|system_control|app_launch|unknown",
    "parameters": {{}},
    "confidence": 0.0-1.0
}}
<|end|>
<|assistant|>
"""
        
        response = self.model(
            prompt,
            max_tokens=150,
            temperature=0.3,
            stop=["<|end|>", "<|user|>"],
            echo=False
        )
        
        text = response['choices'][0]['text'].strip()
        
        try:
            # Extract JSON from response
            json_match = re.search(r'\{.*\}', text, re.DOTALL)
            if json_match:
                parsed = json.loads(json_match.group())
                
                return Intent(
                    category=parsed.get('action', 'unknown'),
                    action=parsed.get('action', 'unknown'),
                    parameters=parsed.get('parameters', {}),
                    confidence=parsed.get('confidence', 0.5),
                    method="llm_based"
                )
        except Exception as e:
            print(f"âŒ LLM parsing error: {e}")
        
        return Intent("error", "parse_failed", {}, 0.0, "llm_error")


class FileSearchHandler:
    """Handle file search operations"""
    
    def __init__(self, vector_store: VectorStore):
        self.store = vector_store
    
    def execute(self, params: Dict) -> Dict:
        """Execute file search"""
        time_filter = params.get('time')
        file_type = params.get('type', '*')
        
        # Build search query
        query_parts = []
        if file_type and file_type != '*':
            query_parts.append(file_type)
        
        query = ' '.join(query_parts) if query_parts else '*'
        
        # Search in database
        results = self.store.search_files(query)
        
        return {
            "status": "success",
            "count": len(results),
            "files": results[:5]  # Limit to 5 results
        }


class SystemControlHandler:
    """Handle system control operations"""
    
    def execute(self, params: Dict) -> Dict:
        """Execute system control command"""
        if 'level' in params:
            level = params['level']
            
            # Volume control
            try:
                subprocess.run(
                    ['amixer', 'set', 'Master', f'{level}%'],
                    check=True,
                    capture_output=True
                )
                return {
                    "status": "success",
                    "message": f"ë³¼ë¥¨ì„ {level}%ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤"
                }
            except subprocess.CalledProcessError:
                return {
                    "status": "error",
                    "message": "ë³¼ë¥¨ ì¡°ì ˆ ì‹¤íŒ¨ (Linux only)"
                }
        
        elif 'app' in params:
            app = params['app']
            
            # App launch
            try:
                subprocess.Popen([app.lower()], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                return {
                    "status": "success",
                    "message": f"{app} ì‹¤í–‰ ì¤‘..."
                }
            except FileNotFoundError:
                return {
                    "status": "error",
                    "message": f"{app}ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
                }
        
        return {"status": "error", "message": "ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹"}


class AIOSCore:
    """AetherOS Core Engine"""
    
    def __init__(self):
        print("ğŸŒŒ AetherOS v0.1.0 - Invisible Intelligence, Everywhere")
        print("=" * 60)
        
        # Initialize
        AetherConfig.init_dirs()
        
        self.vector_store = VectorStore(AetherConfig.DB_PATH)
        self.fast_matcher = FastMatcher()
        self.llm_engine = LLMEngine()
        
        # Handlers
        self.handlers = {
            "search_files": FileSearchHandler(self.vector_store),
            "system_control": SystemControlHandler()
        }
        
        print("âœ… AetherOS initialized")
        print()
    
    def get_context(self) -> Dict:
        """Get current context"""
        return {
            "current_dir": os.getcwd(),
            "timestamp": datetime.now().isoformat(),
            "platform": sys.platform
        }
    
    def process(self, user_input: str) -> Dict:
        """Process user command"""
        start_time = time.time()
        
        # Get context
        context = self.get_context()
        
        # Fast matcher first
        intent = self.fast_matcher.match(user_input)
        
        # If fast matcher fails, use LLM
        if intent.confidence < AetherConfig.FAST_MATCHER_CONFIDENCE_THRESHOLD:
            print("ğŸ§  Using AI for complex understanding...")
            intent = self.llm_engine.parse_intent(user_input, context)
        
        # Execute
        handler = self.handlers.get(intent.action)
        
        if handler:
            result = handler.execute(intent.parameters)
        else:
            result = {
                "status": "error",
                "message": f"'{user_input}' ëª…ë ¹ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤"
            }
        
        exec_time = time.time() - start_time
        
        # Log
        self.vector_store.log_command(
            user_input,
            str(intent),
            json.dumps(result, ensure_ascii=False),
            exec_time
        )
        
        return {
            "intent": intent,
            "result": result,
            "execution_time": exec_time
        }
    
    def format_response(self, result: Dict) -> str:
        """Format result for display"""
        if result['result']['status'] == 'success':
            msg = result['result'].get('message')
            
            if msg:
                return f"âœ… {msg}"
            
            # File search results
            files = result['result'].get('files', [])
            if files:
                response = f"ğŸ“ {result['result']['count']}ê°œì˜ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n"
                for i, file in enumerate(files[:5], 1):
                    response += f"  {i}. {file.get('filename', 'Unknown')}\n"
                return response
            
            return "âœ… ì™„ë£Œ"
        else:
            return f"âŒ {result['result'].get('message', 'ì˜¤ë¥˜ ë°œìƒ')}"


def main():
    """Main entry point"""
    
    # Initialize AetherOS
    aios = AIOSCore()
    
    print("ğŸ’¡ Tip: Type 'help' for examples, 'exit' to quit")
    print()
    
    # REPL loop
    while True:
        try:
            # Get user input
            user_input = input("ğŸŒŒ aether> ").strip()
            
            if not user_input:
                continue
            
            # Special commands
            if user_input.lower() in ['exit', 'quit', 'q']:
                print("ğŸ‘‹ Goodbye!")
                break
            
            if user_input.lower() == 'help':
                print("""
AetherOS Examples:
  
  íŒŒì¼ ê´€ë¦¬:
    - ì–´ì œ ë‹¤ìš´ë¡œë“œí•œ PDF íŒŒì¼ ì°¾ì•„ì¤˜
    - report.pdf íŒŒì¼ ì—´ì–´ì¤˜
  
  ì‹œìŠ¤í…œ ì œì–´:
    - ë³¼ë¥¨ 50
    - ë°ê¸° 70
    - Chrome ì‹¤í–‰
  
  ê¸°íƒ€:
    - help    ë„ì›€ë§
    - exit    ì¢…ë£Œ
                """)
                continue
            
            # Process command
            result = aios.process(user_input)
            
            # Display result
            response = aios.format_response(result)
            print(response)
            
            # Show execution time
            print(f"â±ï¸  {result['execution_time']:.3f}s ({result['intent'].method})")
            print()
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Goodbye!")
            break
        except Exception as e:
            print(f"âŒ Error: {e}")


if __name__ == "__main__":
    main()
